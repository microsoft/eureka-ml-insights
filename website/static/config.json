{
  "benchmarks": [
    {
      "name": "Geometric Reasoning",
      "modality": "multimodal",
      "filePattern": ".*GeoMCQMetric_result_grouped_by_category_report.*",
      "taskDescription": "Cool stuff",
      "capabilityImportance": "TBD",
      "experiments": [
        {
          "title": "Depth and Height",
          "metricsDescription": "Depth and Height",
          "series": [
          ]
        }
      ]
    },
    {
      "name": "MMMU",
      "modality": "multimodal",
      "filePattern": ".*MMMUMetric_result_grouped_by_category_normalized_report.*",
      "taskDescription": "",
      "capabilityImportance": "TBD",
      "experiments": [{
        "title": "Categories",
        "metricsDescription": "Cool stuff",
        "series": [
          {
            "title": "Art and Design",
            "path": ["MMMU", "MMMU"],
            "metric": ["MMMUMetric_result"]
          }
        ]
      }]
    },
    {
      "name": "Image Understanding",
      "modality": "multimodal",
      "filePattern": ".*result_normalized_report.*",
      "taskDescription": "",
      "capabilityImportance": "TBD",
      "experiments": [{
        "title": "",
        "metricsDescription": "Cool stuff",
        "series": [
          {
            "title": "Object Recognition - One Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "OBJECT_RECOGNITION_SINGLE"],
            "metric": ["ObjectRecognitionMetric_result", "correct"]
          },
          {
            "title": "Object Recognition - Two Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "OBJECT_RECOGNITION_PAIRS"],
            "metric": ["ObjectRecognitionMetric_result", "correct"]
          },
          {
            "title": "Visual Prompting - One Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "VISUAL_PROMPTING_SINGLE"],
            "metric": ["ObjectRecognitionMetric_result", "correct"]
          },
          {
            "title": "Visual Prompting - Two Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "VISUAL_PROMPTING_PAIRS"],
            "metric": ["ObjectRecognitionMetric_result", "correct"]
          },
          {
            "title": "Spatial Reasoning - One Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "SPATIAL_REASONING_SINGLE"],
            "metric": ["SpatialAndLayoutReasoningMetric_result", "correct"]
          },
          {
            "title": "Spatial Reasoning - Two Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "SPATIAL_REASONING_PAIRS"],
            "metric": ["SpatialAndLayoutReasoningMetric_result", "correct"]
          }        ,
          {
            "title": "Object Detection - One Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "OBJECT_DETECTION_SINGLE"],
            "metric": ["SpatialAndLayoutReasoningMetric_result", "correct"]
          },
          {
            "title": "Object Detection - Two Object Accuracy",
            "path": ["IMAGE_UNDERSTANDING", "OBJECT_DETECTION_PAIRS"],
            "metric": ["SpatialAndLayoutReasoningMetric_result", "correct"]
          }
        ]
      }]
    },
    {
      "name": "Vision Language Understanding",
      "modality": "multimodal",
      "path": ["IMAGE_UNDERSTANDING", "OBJECT_RECOGNITION_SINGLE"],
      "taskDescription": "",
      "capabilityImportance": "TBD",
      "filePattern": ".*",
      "experiments": [{
        "series": [
          
        ]
      }]
    },
    {
      "name": "IFEval",
      "modality": "language",
      "taskDescription": "",
      "capabilityImportance": "TBD",
      "filePattern": ".*IFEvalMetric_loose_follow_all_instructions_report.*",
      "experiments": [{
        "title": "Follow All Instructions",
        "metricsDescription": "Cool stuff",
        "series": [
          {
            "title": "Follow All Instructions (strict)",
            "path": ["IFEvaL"],
            "description": "",
            "metric": ["IFEvalMetric_strict_follow_all_instructions"]
          },
          {
            "title": "Follow All Instructions (loose)",
            "path": ["IFEvaL"],
            "description": "",
            "metric": ["IFEvalMetric_loose_follow_all_instructions"]
          }
        ]
      }]
    },
    {
      "name": "FlenQA",
      "modality": "language",
      "taskDescription": "",
      "capabilityImportance": "TBD",
      "filePattern": ".*ExactMatch_result_grouped_by_ctx_size.*",
      "experiments": [{
        "title": "Context Size",
        "metricsDescription": "Cool stuff",
        "series": [
          {
            "title": "Context Size: 250",
            "path": ["FlenQA"],
            "metric": ["ExactMatch_result", "250", "correct"]
          },
          {
            "title": "Context Size: 500",
            "path": ["FlenQA"],
            "metric": ["ExactMatch_result", "500", "correct"]
          },
          {
            "title": "Context Size: 1000",
            "path": ["FlenQA"],
            "metric": ["ExactMatch_result", "1000", "correct"]
          },
          {
            "title": "Context Size: 2000",
            "path": ["FlenQA"],
            "metric": ["ExactMatch_result", "2000", "correct"]
          },
          {
            "title": "Context Size: 3000",
            "path": ["FlenQA"],
            "metric": ["ExactMatch_result", "3000", "correct"]
          }
        ]
      }]
    },
    {
      "name": "Kitab",
      "modality": "language",
      "taskDescription": "",
      "capabilityImportance": "TBD",
      "filePattern": ".*AllKitabMetrics_GroupBy_report.*",
      "series": [
        {
          "title": "Satisfied (No-Context)",
          "path": ["Kitab"],
          "description": "",
          "metric": ["KitabMetric_satisfied_rate", "all"]
        },
        {
          "title": "Completeness (No-Context)",
          "path": ["Kitab"],
          "description": "",
          "metric": ["KitabMetric_completeness", "all"]
        }
      ]
    },
    {
      "name": "Toxigen",
      "modality": "language",
      "taskDescription": "",
      "capabilityImportance": "TBD",
      "filePattern": ".*",
      "experiments": [{
        "series": [
          
        ]
      }]
    }
  ],
  "capability_mapping": [
    {
      "capability": "Information Retrieval Fact Recall",
      "modality": "language",
      "path": ["kitab", "ONE_BOOK_CONSTRAINT_PIPELINE"],
      "metric": ["KitabMetric_satisfied_rate"],
      "run": "average",
      "description": "Task: Retrieving long-form information from the model's parametric knowledge or from given input context with filtering constraints. Capability importance: All information retrieval tasks involve some form of constraint that defines the retrieval query. However, other simpler IR benchmarks only test for short-form generation (finding a single fact) and for a single con-straint. Being able to answer more complex queries is relevant to advanced search and information finding. State-of-the-art: Constrained retrieval from parametric knowledge is still prone to major irrelevance and fact fabrication with constraint satisfaction being less than 60%. Constrained retrieval from given input context is significantly better in overall, but for queries with more than one constraint constraint satisfaction and completeness drop to less than 70% and 60% respectively."
    },
    {
      "capability": "Information Retrieval Fact Precision",
      "modality": "language",
      "path": ["kitab", "ONE_BOOK_CONSTRAINT_PIPELINE"],
      "metric": ["KitabMetric_completeness"],
      "run": "average",
      "description": "Task: Retrieving long-form information from the model's parametric knowledge or from given input context with filtering constraints. Capability importance: All information retrieval tasks involve some form of constraint that defines the retrieval query. However, other simpler IR benchmarks only test for short-form generation (finding a single fact) and for a single con-straint. Being able to answer more complex queries is relevant to advanced search and information finding. State-of-the-art: Constrained retrieval from parametric knowledge is still prone to major irrelevance and fact fabrication with constraint satisfaction being less than 60%. Constrained retrieval from given input context is significantly better in overall, but for queries with more than one constraint constraint satisfaction and completeness drop to less than 70% and 60% respectively."
    },
    {
      "capability": "Instruction Following",
      "modality": "language",
      "path": ["IFEval"],
      "metric": ["IFEvalMetric_strict_follow_all_instructions"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Long Context QA Average",
      "modality": "language",
      "path": ["FlenQA"],
      "metric": ["ExactMatch_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Long Context QA Longest Context (3K)",
      "modality": "language",
      "path": ["FlenQA"],
      "metric": ["ExactMatch_result", "3000", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Toxicity Detection",
      "modality": "language",
      "path": ["Toxigen", "Discriminative", "9K"],
      "metric": ["ExactMatch_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Geometric Reasoning",
      "modality": "multimodal",
      "path": ["Geometric-Reasoning"],
      "metric": ["GeoMCQMetric_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Multimodal QA",
      "modality": "multimodal",
      "path": ["MMMU", "MMMU"],
      "metric": ["MMMUMetric_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Object Recognition",
      "modality": "multimodal",
      "path": ["IMAGE_UNDERSTANDING", "OBJECT_RECOGNITION_SINGLE"],
      "metric": ["ObjectRecognitionMetric_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Object Detection (AP50)",
      "modality": "multimodal",
      "path": ["IMAGE_UNDERSTANDING", "OBJECT_DETECTION_SINGLE"],
      "metric": ["CocoObjectDetectionMetric_result", "AP50"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Visual Prompting",
      "modality": "multimodal",
      "path": ["IMAGE_UNDERSTANDING", "VISUAL_PROMPTING_SINGLE"],
      "metric": ["ObjectRecognitionMetric_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Spatial Reasoning",
      "modality": "multimodal",
      "path": ["IMAGE_UNDERSTANDING", "SPATIAL_REASONING_SINGLE"],
      "metric": ["SpatialAndLayoutReasoningMetric_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Spatial Map Understanding",
      "modality": "multimodal",
      "path": ["VISION_LANGUAGE", "SPATIAL_MAP"],
      "metric": ["SpatialAndLayoutReasoningMetricMap_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Navigation",
      "modality": "multimodal",
      "path": ["VISION_LANGUAGE", "MAZE"],
      "metric": ["SpatialAndLayoutReasoningMetricMaze_result", "correct"],
      "run": "average",
      "description": "TBD"
    },
    {
      "capability": "Counting in a Grid",
      "modality": "multimodal",
      "path": ["VISION_LANGUAGE", "SPATIAL_GRID"],
      "metric": ["SpatialAndLayoutReasoningMetricGrid_result", "correct"],
      "run": "average",
      "description": "TBD"
    }
  ],
  "model_families": [
    "claude", "gemini", "llama", "gpt", "mistral", "llava"
  ],
  "model_list": [
    {
      "model_family": "Claude",
      "model": "Claude-3-Opus",
      "color": "#4762D6",
      "modality": ["vision", "language"]
    },
    {
      "model_family": "Claude",
      "model": "Claude-3_5-Sonnet",
      "color": "#4762D6",
      "modality": ["vision", "language"]
    },
    {
      "model_family": "Gemini",
      "model": "Gemini-1_5-Pro",
      "color": "#AE8C00",
      "modality": ["vision", "language"]
    },
    {
      "model_family": "Llama",
      "model": "Llama-3-70B",
      "color": "#058801",
      "modality": ["language"]
    },
    {
      "model_family": "Llama",
      "model": "Llama-3_1-405B",
      "color": "#71A920",
      "modality": ["language"]
    },
    {
      "model_family": "Llama",
      "model": "Llama-3_1-70B",
      "color": "#65D060",
      "modality": ["language"]
    },
    {
      "model_family": "GPT",
      "model": "GPT-4-1106-Preview",
      "color": "#E3008C",
      "modality": ["language"]
    },
    {
      "model_family": "GPT",
      "model": "GPT-4o-2024-05-13",
      "color": "#B61A40",
      "modality": ["vision", "language"]
    },
    {
      "model_family": "GPT",
      "model": "GPT-4-Vision-Preview",
      "color": "#E3008C",
      "modality": ["vision"]
    },
    {
      "model_family": "GPT",
      "model": "GPT-4-Turbo-2024-04-09",
      "color": "#B61A40",
      "modality": ["vision"]
    },
    {
      "model_family": "Mistral",
      "model": "Mistral_Large_2_2407",
      "color": "#E86B24",
      "modality": ["language"]
    },
    {
      "model_family": "Llava",
      "model": "Llava-1_6-34B",
      "color": "#E86B24",
      "modality": ["language"]
    }
  ]
}