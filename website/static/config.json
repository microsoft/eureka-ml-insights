{
  "benchmarks": [
    "Kitab"
  ],
  "experiments": [
    {
      "experiment": "ONE_BOOK_CONSTRAINT_PIPELINE",
      "metrics": [
        "all_correct",
        "completeness",
        "satisfied_rate",
        "not_from_author_rate",
        "unsatisfied_rate"
      ]
    },
    {
      "experiment": "ONE_BOOK_CONSTRAINT_PIPELINE_SELF_CONTEXT",
      "metrics": [
        "all_correct",
        "completeness",
        "satisfied_rate",
        "not_from_author_rate",
        "unsatisfied_rate"
      ]
    },
    {
      "experiment": "ONE_BOOK_CONSTRAINT_PIPELINE_WITH_CONTEXT",
      "metrics": [
        "all_correct",
        "completeness",
        "satisfied_rate",
        "not_from_author_rate",
        "unsatisfied_rate"
      ]
    },
    {
      "experiment": "TWO_BOOK_CONSTRAINT_PIPELINE",
      "metrics": [
        "all_correct",
        "completeness",
        "satisfied_rate",
        "not_from_author_rate",
        "unsatisfied_rate"
      ]
    },
    {
      "experiment": "TWO_BOOK_CONSTRAINT_PIPELINE_WITH_CONTEXT",
      "metrics": [
        "all_correct",
        "completeness",
        "satisfied_rate",
        "not_from_author_rate",
        "unsatisfied_rate"
      ]
    }
  ],
  "model_list": [
    {
      "model_family": "Claude",
      "models": [
        "Claude-3_5-Sonnet",
        "Claude-3-Opus"
      ]
    },
    {
      "model_family": "Gemini",
      "models": [
        "Gemini-1_5-Pro"
      ]
    },
    {
      "model_family": "GPT",
      "models": [
        "GPT-4-1106-Preview",
        "GPT-4o-2024-05-13"
      ]
    },
    {
      "model_family": "Llama",
      "models": [
        "Llama-3-70B",
        "Llama-3_1-70B"
      ]
    },
    {
      "model_family": "Mistral",
      "models": [
        "Mistral_Large_2_2407"
      ]
    }
  ]
}